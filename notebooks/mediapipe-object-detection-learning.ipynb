{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lars-Hecker/backtrader/blob/master/notebooks/mediapipe-object-detection-learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyPuNcVXq8s9"
      },
      "source": [
        "# MediaPipe Object Detection Learning\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ShawnHymel/google-coral-micro-object-detection/blob/master/notebooks/mediapipe-object-detection-learning.ipynb)\n",
        "\n",
        "```\n",
        "Original authors: MediaPipeline (Google)\n",
        "Modified by: Shawn Hymel\n",
        "Date: December 16, 2023\n",
        "```\n",
        "\n",
        "Use transfer learning with Google MediaPipe to build a custom object detection model. Based on the example code from https://developers.google.com/mediapipe/solutions/customization/object_detector.\n",
        "\n",
        "> **Note:** This script has been verified with TensorFlow v2.15.0.\n",
        "\n",
        "To use this script, upload your dataset in [Pascal VOC format](http://host.robots.ox.ac.uk/pascal/VOC/) in an archive named *dataset.zip*. You can use a labeling tool like [labelImg](https://github.com/HumanSignal/labelImg) or [Make Sense](https://www.makesense.ai/) to create bounding box annotations in the Pascal VOC format.\n",
        "\n",
        "\n",
        "Your data should be in the following format. Note that the directory names \"Annotations\" and \"images\" must be exactly as shown (with the capital 'A' and lowercase 'i').\n",
        "\n",
        "```\n",
        "dataset.zip\n",
        "├── Annotations/\n",
        "│   ├── image.01.xml\n",
        "│   ├── image.02.xml\n",
        "│   ├── ...\n",
        "└── images/\n",
        "    ├── image.01.jpg\n",
        "    ├── image.02.jpg\n",
        "    └── ...\n",
        "```\n",
        "\n",
        "Run through all the cells. Adjust the hyperparameters (`hparams`) as needed to achieve the desired accuracy. Ideally, you want your average precision (AP) to be greater than 90% to get a useful object detection model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "B1JOF-3nPnbl"
      },
      "outputs": [],
      "source": [
        "#@title License information\n",
        "# Copyright 2023 The MediaPipe Authors.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-vOxSHjPb1S"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "71Vwn9W6rQju",
        "outputId": "66bf51ad-00e9-4b2b-ef54-03e70537ad35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Collecting mediapipe-model-maker\n",
            "  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe-model-maker) (1.4.0)\n",
            "Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mediapipe-model-maker) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from mediapipe-model-maker) (4.12.0.88)\n",
            "INFO: pip is looking at multiple versions of mediapipe-model-maker to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mediapipe-model-maker\n",
            "  Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tensorflow>=2.10 in /usr/local/lib/python3.12/dist-packages (from mediapipe-model-maker) (2.19.0)\n",
            "  Downloading mediapipe_model_maker-0.2.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading mediapipe_model_maker-0.2.1.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading mediapipe_model_maker-0.2.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading mediapipe_model_maker-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.12/dist-packages (from mediapipe-model-maker) (4.9.9)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.12/dist-packages (from mediapipe-model-maker) (0.16.1)\n",
            "Collecting tf-models-official==2.11.6 (from mediapipe-model-maker)\n",
            "  Downloading tf_models_official-2.11.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (11.3.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (2.187.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (4.2.2)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (1.7.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (3.10.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (4.12.0.88)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (2.0.10)\n",
            "Collecting pyyaml<6.0,>=5.1 (from tf-models-official==2.11.6->mediapipe-model-maker)\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m No available output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Failed to build 'pyyaml' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
            "\u001b[0m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1022  100  1022    0     0   7073      0 --:--:-- --:--:-- --:--:--  7097\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [1,423 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,160 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:12 https://packages.cloud.google.com/apt coral-edgetpu-stable/main all Packages [1,865 B]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [6,888 B]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,840 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.8 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,561 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,499 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,059 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,273 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,895 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Fetched 37.7 MB in 5s (7,906 kB/s)\n",
            "Reading package lists... Done\n",
            "W: https://packages.cloud.google.com/apt/dists/coral-edgetpu-stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 0s (18.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install MediaPipe and Edge TPU compiler\n",
        "!python --version\n",
        "!pip install --upgrade pip\n",
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "! sudo apt-get update\n",
        "! sudo apt-get install edgetpu-compiler\n",
        "!pip install mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S6i8DzRmWP2N",
        "outputId": "37e189bc-af2c-4d31-adcd-82fbe38da87a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mediapipe_model_maker'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2753939664.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe_model_maker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe_model_maker'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from mediapipe_model_maker import object_detector, quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDCndaU1O_Tk"
      },
      "outputs": [],
      "source": [
        "# Check TensorFlow version\n",
        "print(tf.__version__)\n",
        "assert tf.__version__.startswith('2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdZb8awuq7gx"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "BASE_PATH = \".\"\n",
        "DATASET_ZIP_PATH = os.path.join(BASE_PATH, \"dataset.zip\")\n",
        "DATASET_PATH = os.path.join(BASE_PATH, \"dataset/\")\n",
        "TRAIN_SPLIT = 0.8\n",
        "EXPORT_PATH = os.path.join(BASE_PATH, \"exported_models/\")\n",
        "TFLITE_FLOAT32_NAME = \"model.tflite\"\n",
        "TFLITE_INT8_NAME = \"model_int8.tflite\"\n",
        "METADATA_PATH = os.path.join(EXPORT_PATH, \"metadata.json\")\n",
        "METADATA_H_NAME = \"metadata.hpp\"\n",
        "METADATA_H_PATH = os.path.join(EXPORT_PATH, METADATA_H_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTrJMYmctlMQ"
      },
      "source": [
        "## Create dataset\n",
        "\n",
        "Load and prepare the dataset for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CNE-9xBr7Qs"
      },
      "outputs": [],
      "source": [
        "# Unzip dataset\n",
        "!rm -rf {DATASET_PATH}\n",
        "!unzip -q {DATASET_ZIP_PATH} -d {DATASET_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE0saod5sKtn"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = object_detector.Dataset.from_pascal_voc_folder(DATASET_PATH)\n",
        "\n",
        "# Split the dataset into separate training and validation sets\n",
        "train_data, validation_data = data.split(TRAIN_SPLIT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf6EwReH-3Jy"
      },
      "source": [
        "## Train object detection model\n",
        "\n",
        "Use transfer learning to retrain a model. Gather more/better data and adjust the hyperparameters (`hparams`) to ideally obtain a `total_loss` of less than 0.1 and an average precision (AP) of greater than 0.9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX8RXjnauguy"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained model and specify hyperparameters\n",
        "spec = object_detector.SupportedModels.MOBILENET_V2_I320\n",
        "hparams = object_detector.HParams(\n",
        "    learning_rate = 0.3,\n",
        "    batch_size=8,\n",
        "    epochs=50,\n",
        "    export_dir=EXPORT_PATH,\n",
        ")\n",
        "options = object_detector.ObjectDetectorOptions(\n",
        "    supported_model=spec,\n",
        "    hparams=hparams,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLTzpJYFAIt-"
      },
      "outputs": [],
      "source": [
        "# Retrain model\n",
        "model = object_detector.ObjectDetector.create(\n",
        "    train_data=train_data,\n",
        "    validation_data=validation_data,\n",
        "    options=options\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzmHFaQCAlfO"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performance\n",
        "loss, coco_metrics = model.evaluate(\n",
        "    validation_data,\n",
        "    batch_size=4,\n",
        ")\n",
        "print(f\"Validation loss: {loss}\")\n",
        "print(f\"Validation metrics: {coco_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3BoPclpBFUN"
      },
      "source": [
        "## Export model\n",
        "\n",
        "Save the model in three different formats:\n",
        "\n",
        " 1. 32-bit floating point TensorFlow Lite (TFLite)\n",
        " 2. 8-bit integer quantized TFLite\n",
        " 3. TPU compiled and quantized TFLite|\n",
        "\n",
        "Additionally, save the metadata (anchor box information) in a .h file that a resource-constrained device can recalculate the anchor boxes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dttq5K2bA_Pn"
      },
      "outputs": [],
      "source": [
        "# Export 32-bit float model\n",
        "model.export_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry2xxZm4CUIP"
      },
      "outputs": [],
      "source": [
        "# Perform post-training quantization (8-bit integer) and save quantized model\n",
        "quantization_config = quantization.QuantizationConfig.for_int8(\n",
        "    representative_data=validation_data,\n",
        ")\n",
        "model.restore_float_ckpt()\n",
        "model.export_model(\n",
        "    model_name=TFLITE_INT8_NAME,\n",
        "    quantization_config=quantization_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mljgQv4sHFkj"
      },
      "outputs": [],
      "source": [
        "# Compile the model for Edge TPU\n",
        "!edgetpu_compiler -s -o {EXPORT_PATH} {os.path.join(EXPORT_PATH, TFLITE_INT8_NAME)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HtGzw_rgeoJ"
      },
      "outputs": [],
      "source": [
        "# Import model metadata\n",
        "with open(METADATA_PATH, 'r') as file:\n",
        "    metadata = json.load(file)\n",
        "\n",
        "# Parse metadata\n",
        "custom_metadata = metadata['subgraph_metadata'][0]['custom_metadata'][0]\n",
        "anchors = custom_metadata['data']['ssd_anchors_options']['fixed_anchors_schema']['anchors']\n",
        "num_values_per_keypoint = custom_metadata['data']['tensors_decoding_options']['num_values_per_keypoint']\n",
        "apply_exponential_on_box_size = custom_metadata['data']['tensors_decoding_options']['apply_exponential_on_box_size']\n",
        "x_scale = custom_metadata['data']['tensors_decoding_options']['x_scale']\n",
        "y_scale = custom_metadata['data']['tensors_decoding_options']['y_scale']\n",
        "w_scale = custom_metadata['data']['tensors_decoding_options']['w_scale']\n",
        "h_scale = custom_metadata['data']['tensors_decoding_options']['h_scale']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To1IvviFsYls"
      },
      "outputs": [],
      "source": [
        "# Figure out when the resets (sectors) occur, the x/y increases, and width/height of anchors\n",
        "reset_idxs = []\n",
        "y_strides = []\n",
        "x_strides = []\n",
        "widths_per_section = []\n",
        "widths = []\n",
        "heights_per_section = []\n",
        "heights = []\n",
        "reset_flag = True\n",
        "x_stride_flag = True\n",
        "width_flag = True\n",
        "\n",
        "# Go through all the anchors\n",
        "num_anchors = len(anchors)\n",
        "for i in range(num_anchors):\n",
        "\n",
        "    # Store the first index\n",
        "    if i == 0:\n",
        "        reset_idxs.append(i)\n",
        "\n",
        "    # Only measure strides on not 0 indexes\n",
        "    else:\n",
        "\n",
        "        # New section: reset flags\n",
        "        if anchors[i]['y_center'] < anchors[i - 1]['y_center']:\n",
        "            reset_idxs.append(i)\n",
        "            reset_flag = True\n",
        "            x_stride_flag = True\n",
        "            width_flag = True\n",
        "\n",
        "        # Measure Y increase (stride)\n",
        "        if reset_flag:\n",
        "            if anchors[i]['y_center'] > anchors[i - 1]['y_center']:\n",
        "                y_inc = anchors[i]['y_center'] - anchors[i - 1]['y_center']\n",
        "                y_strides.append(round(y_inc, 5))\n",
        "                reset_flag = False\n",
        "\n",
        "        # Measure X increase (stride)\n",
        "        if x_stride_flag:\n",
        "            if anchors[i]['x_center'] > anchors[i - 1]['x_center']:\n",
        "                x_inc = anchors[i]['x_center'] - anchors[i - 1]['x_center']\n",
        "                x_strides.append(round(x_inc, 5))\n",
        "                x_stride_flag = False\n",
        "\n",
        "    # Record widths and heights of the anchor boxes\n",
        "    if width_flag:\n",
        "        if i != 0 and anchors[i]['x_center'] > anchors[i - 1]['x_center']:\n",
        "            widths.append(widths_per_section)\n",
        "            widths_per_section = []\n",
        "            heights.append(heights_per_section)\n",
        "            heights_per_section = []\n",
        "            width_flag = False\n",
        "        else:\n",
        "            width = anchors[i]['width']\n",
        "            widths_per_section.append(round(width, 5))\n",
        "            height = anchors[i]['height']\n",
        "            heights_per_section.append(round(height, 5))\n",
        "\n",
        "# Calculate the number of sectors\n",
        "num_sectors = len(reset_idxs)\n",
        "\n",
        "# Calculate the number of anchors per coordinate\n",
        "num_anchors_per_coord = len(widths[0])\n",
        "\n",
        "# Calculate the number of Xs in each Y\n",
        "num_xs_per_y = []\n",
        "for sector in range(num_sectors):\n",
        "    num_xs_per_y.append(int(1.0 / x_strides[sector] * num_anchors_per_coord))\n",
        "\n",
        "print(f\"Number of anchors {num_anchors}\")\n",
        "print(f\"Number of sectors: {num_sectors}\")\n",
        "print(f\"Number of anchors per coordinate: {num_anchors_per_coord}\")\n",
        "print(f\"Reset indexes: {reset_idxs}\")\n",
        "print(f\"Number of Xs per Y: {num_xs_per_y}\")\n",
        "print(f\"X strides: {x_strides}\")\n",
        "print(f\"Y strides: {y_strides}\")\n",
        "print(\"Widths:\")\n",
        "for wps in widths:\n",
        "    print(wps)\n",
        "print(\"Heights:\")\n",
        "for hps in heights:\n",
        "    print(hps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKyxi0L9hB-5"
      },
      "outputs": [],
      "source": [
        "# Generate header file for metadata information\n",
        "h_str = f\"\"\"\\\n",
        "// Filename: {METADATA_H_NAME}\n",
        "\n",
        "#ifndef METADATA_HPP\n",
        "#define METADATA_HPP\n",
        "\n",
        "namespace metadata {{\n",
        "    constexpr unsigned int num_anchors = {num_anchors};\n",
        "    constexpr int apply_exp_scaling = {1 if apply_exponential_on_box_size else 0};\n",
        "    constexpr float x_scale = {x_scale};\n",
        "    constexpr float y_scale = {y_scale};\n",
        "    constexpr float w_scale = {w_scale};\n",
        "    constexpr float h_scale = {h_scale};\n",
        "    constexpr unsigned int num_sectors = {num_sectors};\n",
        "    constexpr unsigned int num_anchors_per_coord = {num_anchors_per_coord};\n",
        "\"\"\"\n",
        "\n",
        "# Print reset indexes\n",
        "h_str += \"    constexpr unsigned int reset_idxs[] = {\\r\\n\"\n",
        "h_str += \"        \"\n",
        "for i in range(num_sectors):\n",
        "    h_str += f\"{reset_idxs[i]}\"\n",
        "    if i < num_sectors - 1:\n",
        "        h_str += \", \"\n",
        "h_str += \"\\r\\n\"\n",
        "h_str += \"    };\\r\\n\"\n",
        "\n",
        "# Print the number of X values for each Y value\n",
        "h_str += \"    constexpr unsigned int num_xs_per_y[] = {\\r\\n\"\n",
        "h_str += \"        \"\n",
        "for i in range(num_sectors):\n",
        "    h_str += f\"{num_xs_per_y[i]}\"\n",
        "    if i < num_sectors - 1:\n",
        "        h_str += \", \"\n",
        "h_str += \"\\r\\n\"\n",
        "h_str += \"    };\\r\\n\"\n",
        "\n",
        "# Print the X strides\n",
        "h_str += \"    constexpr float x_strides[] = {\\r\\n\"\n",
        "h_str += \"        \"\n",
        "for i in range(num_sectors):\n",
        "    h_str += f\"{x_strides[i]}\"\n",
        "    if i < num_sectors - 1:\n",
        "        h_str += \", \"\n",
        "h_str += \"\\r\\n\"\n",
        "h_str += \"    };\\r\\n\"\n",
        "\n",
        "# Print the Y strides\n",
        "h_str += \"    constexpr float y_strides[] = {\\r\\n\"\n",
        "h_str += \"        \"\n",
        "for i in range(num_sectors):\n",
        "    h_str += f\"{y_strides[i]}\"\n",
        "    if i < num_sectors - 1:\n",
        "        h_str += \", \"\n",
        "h_str += \"\\r\\n\"\n",
        "h_str += \"    };\\r\\n\"\n",
        "\n",
        "# Print the anchor widths for each section\n",
        "h_str += f\"    constexpr float widths[{num_sectors}][{len(widths[0])}] = {{\\r\\n\"\n",
        "for i in range(num_sectors):\n",
        "    h_str += \"        {\"\n",
        "    for j in range(len(widths[0])):\n",
        "        h_str += f\"{widths[i][j]}\"\n",
        "        if j < len(widths[0]) - 1:\n",
        "            h_str += \", \"\n",
        "    h_str += \"}\"\n",
        "    if i < num_sectors - 1:\n",
        "        h_str += \",\"\n",
        "    h_str += \"\\r\\n\"\n",
        "h_str += \"    };\\r\\n\"\n",
        "\n",
        "# Print the anchor heights for each section\n",
        "h_str += f\"    constexpr float heights[{num_sectors}][{len(heights[0])}] = {{\\r\\n\"\n",
        "for i in range(num_sectors):\n",
        "    h_str += \"        {\"\n",
        "    for j in range(len(heights[0])):\n",
        "        h_str += f\"{heights[i][j]}\"\n",
        "        if j < len(heights[0]) - 1:\n",
        "            h_str += \", \"\n",
        "    h_str += \"}\"\n",
        "    if i < num_sectors - 1:\n",
        "        h_str += \",\"\n",
        "    h_str += \"\\r\\n\"\n",
        "h_str += \"    };\\r\\n\"\n",
        "\n",
        "# Close header file\n",
        "h_str += \"\"\"\\\n",
        "}\n",
        "\n",
        "#endif // METADATA_HPP\n",
        "\"\"\"\n",
        "\n",
        "# write to .h file\n",
        "with open(METADATA_H_PATH, 'w') as file:\n",
        "    file.write(h_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_ieJWMdLLof"
      },
      "outputs": [],
      "source": [
        "# Zip exported models\n",
        "zip_name = os.path.normpath(EXPORT_PATH).split(os.sep)[-1] + \".zip\"\n",
        "zip_path = os.path.join(BASE_PATH, zip_name)\n",
        "!zip -q -r {zip_path} {EXPORT_PATH}/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt_5cU4ZOGGY"
      },
      "outputs": [],
      "source": [
        "# Download exported models\n",
        "files.download(zip_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8T3qKUMjYkK"
      },
      "outputs": [],
      "source": [
        "!zip -q -r exported_models.zip {os.path.join(EXPORT_PATH, \"*\")}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHwO7UCdXtMZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}